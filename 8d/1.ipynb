{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 자연어 처리\n",
    "\n",
    "-문장을 바로 처리하기 힘들기 때문에 단어로 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doce = ['There is a boy.',\n",
    " 'The boy is ver pretty.',\n",
    "  'The vernacular was not the stuff of parliamentary propriety — “I need to take a minute,” he wrote about stepping back from the trail — but that was the point, as is often the case with Fetterman. At 6-foot-8, with a shiny pate, a salt-and-pepper goatee, tattooed arms and a sports-bar fashion sense, Fetterman was announcing from a hospital bed that even in illness he remained a different kind of Democrat.',\n",
    "  'Republicans were set to choose Tuesday among three leading Senate candidates in a hard-fought primary contest — physician and celebrity Mehmet Oz, backed by Trump; financier David McCormick; and upstart Kathy Barnette, who on Jan. 6, 2021, participated in the “Stop the Steal” rally that preceded the violent assault on the U.S. Capitol.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['there', 'is', 'a', 'boy'],\n",
       " ['the', 'boy', 'is', 'ver', 'pretty'],\n",
       " ['the',\n",
       "  'vernacular',\n",
       "  'was',\n",
       "  'not',\n",
       "  'the',\n",
       "  'stuff',\n",
       "  'of',\n",
       "  'parliamentary',\n",
       "  'propriety',\n",
       "  '—',\n",
       "  '“i',\n",
       "  'need',\n",
       "  'to',\n",
       "  'take',\n",
       "  'a',\n",
       "  'minute,”',\n",
       "  'he',\n",
       "  'wrote',\n",
       "  'about',\n",
       "  'stepping',\n",
       "  'back',\n",
       "  'from',\n",
       "  'the',\n",
       "  'trail',\n",
       "  '—',\n",
       "  'but',\n",
       "  'that',\n",
       "  'was',\n",
       "  'the',\n",
       "  'point,',\n",
       "  'as',\n",
       "  'is',\n",
       "  'often',\n",
       "  'the',\n",
       "  'case',\n",
       "  'with',\n",
       "  'fetterman',\n",
       "  'at',\n",
       "  '6-foot-8,',\n",
       "  'with',\n",
       "  'a',\n",
       "  'shiny',\n",
       "  'pate,',\n",
       "  'a',\n",
       "  'salt-and-pepper',\n",
       "  'goatee,',\n",
       "  'tattooed',\n",
       "  'arms',\n",
       "  'and',\n",
       "  'a',\n",
       "  'sports-bar',\n",
       "  'fashion',\n",
       "  'sense,',\n",
       "  'fetterman',\n",
       "  'was',\n",
       "  'announcing',\n",
       "  'from',\n",
       "  'a',\n",
       "  'hospital',\n",
       "  'bed',\n",
       "  'that',\n",
       "  'even',\n",
       "  'in',\n",
       "  'illness',\n",
       "  'he',\n",
       "  'remained',\n",
       "  'a',\n",
       "  'different',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'democrat'],\n",
       " ['republicans',\n",
       "  'were',\n",
       "  'set',\n",
       "  'to',\n",
       "  'choose',\n",
       "  'tuesday',\n",
       "  'among',\n",
       "  'three',\n",
       "  'leading',\n",
       "  'senate',\n",
       "  'candidates',\n",
       "  'in',\n",
       "  'a',\n",
       "  'hard-fought',\n",
       "  'primary',\n",
       "  'contest',\n",
       "  '—',\n",
       "  'physician',\n",
       "  'and',\n",
       "  'celebrity',\n",
       "  'mehmet',\n",
       "  'oz,',\n",
       "  'backed',\n",
       "  'by',\n",
       "  'trump;',\n",
       "  'financier',\n",
       "  'david',\n",
       "  'mccormick;',\n",
       "  'and',\n",
       "  'upstart',\n",
       "  'kathy',\n",
       "  'barnette,',\n",
       "  'who',\n",
       "  'on',\n",
       "  'jan',\n",
       "  '6,',\n",
       "  '2021,',\n",
       "  'participated',\n",
       "  'in',\n",
       "  'the',\n",
       "  '“stop',\n",
       "  'the',\n",
       "  'steal”',\n",
       "  'rally',\n",
       "  'that',\n",
       "  'preceded',\n",
       "  'the',\n",
       "  'violent',\n",
       "  'assault',\n",
       "  'on',\n",
       "  'the',\n",
       "  'us',\n",
       "  'capitol']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for s in doce:\n",
    "    s2= s.replace('.', '')\n",
    "    s2 = s2.lower()\n",
    "    data.append(s2.split())\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딕셔너리(dictionary)\n",
    "- ``사람은 누구든지 \"이름\" = \"홍길동\", \"생일\" = \"몇 월 며칠\" 등으로 구별할 수 있다. 파이썬은 영리하게도 이러한 대응 관계를 나타낼 수 있는 자료형을 가지고 있다. 요즘 사용하는 대부분의 언어도 이러한 대응 관계를 나타내는 자료형을 갖고 있는데, 이를 연관 배열(Associative array) 또는 해시(Hash)라고 한다.``\n",
    "\n",
    "- ``ex) dic = {'name':'pey', 'phone':'0119993323', 'birth': '1118'}``\n",
    "\n",
    "|dic|key|value|\n",
    "|---|---|-----|\n",
    "|---|name|pey|\n",
    "|---|phone|01199993323|\n",
    "|---|birth|1118|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'there': 0,\n",
       " 'is': 1,\n",
       " 'a': 2,\n",
       " 'boy': 3,\n",
       " 'the': 4,\n",
       " 'ver': 5,\n",
       " 'pretty': 6,\n",
       " 'vernacular': 7,\n",
       " 'was': 8,\n",
       " 'not': 9,\n",
       " 'stuff': 10,\n",
       " 'of': 11,\n",
       " 'parliamentary': 12,\n",
       " 'propriety': 13,\n",
       " '—': 14,\n",
       " '“i': 15,\n",
       " 'need': 16,\n",
       " 'to': 17,\n",
       " 'take': 18,\n",
       " 'minute,”': 19,\n",
       " 'he': 20,\n",
       " 'wrote': 21,\n",
       " 'about': 22,\n",
       " 'stepping': 23,\n",
       " 'back': 24,\n",
       " 'from': 25,\n",
       " 'trail': 26,\n",
       " 'but': 27,\n",
       " 'that': 28,\n",
       " 'point,': 29,\n",
       " 'as': 30,\n",
       " 'often': 31,\n",
       " 'case': 32,\n",
       " 'with': 33,\n",
       " 'fetterman': 34,\n",
       " 'at': 35,\n",
       " '6-foot-8,': 36,\n",
       " 'shiny': 37,\n",
       " 'pate,': 38,\n",
       " 'salt-and-pepper': 39,\n",
       " 'goatee,': 40,\n",
       " 'tattooed': 41,\n",
       " 'arms': 42,\n",
       " 'and': 43,\n",
       " 'sports-bar': 44,\n",
       " 'fashion': 45,\n",
       " 'sense,': 46,\n",
       " 'announcing': 47,\n",
       " 'hospital': 48,\n",
       " 'bed': 49,\n",
       " 'even': 50,\n",
       " 'in': 51,\n",
       " 'illness': 52,\n",
       " 'remained': 53,\n",
       " 'different': 54,\n",
       " 'kind': 55,\n",
       " 'democrat': 56,\n",
       " 'republicans': 57,\n",
       " 'were': 58,\n",
       " 'set': 59,\n",
       " 'choose': 60,\n",
       " 'tuesday': 61,\n",
       " 'among': 62,\n",
       " 'three': 63,\n",
       " 'leading': 64,\n",
       " 'senate': 65,\n",
       " 'candidates': 66,\n",
       " 'hard-fought': 67,\n",
       " 'primary': 68,\n",
       " 'contest': 69,\n",
       " 'physician': 70,\n",
       " 'celebrity': 71,\n",
       " 'mehmet': 72,\n",
       " 'oz,': 73,\n",
       " 'backed': 74,\n",
       " 'by': 75,\n",
       " 'trump;': 76,\n",
       " 'financier': 77,\n",
       " 'david': 78,\n",
       " 'mccormick;': 79,\n",
       " 'upstart': 80,\n",
       " 'kathy': 81,\n",
       " 'barnette,': 82,\n",
       " 'who': 83,\n",
       " 'on': 84,\n",
       " 'jan': 85,\n",
       " '6,': 86,\n",
       " '2021,': 87,\n",
       " 'participated': 88,\n",
       " '“stop': 89,\n",
       " 'steal”': 90,\n",
       " 'rally': 91,\n",
       " 'preceded': 92,\n",
       " 'violent': 93,\n",
       " 'assault': 94,\n",
       " 'us': 95,\n",
       " 'capitol': 96}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = {}\n",
    "n = 0\n",
    "\n",
    "for doc in data:\n",
    "    for word in doc:\n",
    "        if word not in bow:\n",
    "            bow[word] = n\n",
    "            n += 1\n",
    "            \n",
    "            \n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'there',\n",
       " 1: 'is',\n",
       " 2: 'a',\n",
       " 3: 'boy',\n",
       " 4: 'the',\n",
       " 5: 'ver',\n",
       " 6: 'pretty',\n",
       " 7: 'vernacular',\n",
       " 8: 'was',\n",
       " 9: 'not',\n",
       " 10: 'stuff',\n",
       " 11: 'of',\n",
       " 12: 'parliamentary',\n",
       " 13: 'propriety',\n",
       " 14: '—',\n",
       " 15: '“i',\n",
       " 16: 'need',\n",
       " 17: 'to',\n",
       " 18: 'take',\n",
       " 19: 'minute,”',\n",
       " 20: 'he',\n",
       " 21: 'wrote',\n",
       " 22: 'about',\n",
       " 23: 'stepping',\n",
       " 24: 'back',\n",
       " 25: 'from',\n",
       " 26: 'trail',\n",
       " 27: 'but',\n",
       " 28: 'that',\n",
       " 29: 'point,',\n",
       " 30: 'as',\n",
       " 31: 'often',\n",
       " 32: 'case',\n",
       " 33: 'with',\n",
       " 34: 'fetterman',\n",
       " 35: 'at',\n",
       " 36: '6-foot-8,',\n",
       " 37: 'shiny',\n",
       " 38: 'pate,',\n",
       " 39: 'salt-and-pepper',\n",
       " 40: 'goatee,',\n",
       " 41: 'tattooed',\n",
       " 42: 'arms',\n",
       " 43: 'and',\n",
       " 44: 'sports-bar',\n",
       " 45: 'fashion',\n",
       " 46: 'sense,',\n",
       " 47: 'announcing',\n",
       " 48: 'hospital',\n",
       " 49: 'bed',\n",
       " 50: 'even',\n",
       " 51: 'in',\n",
       " 52: 'illness',\n",
       " 53: 'remained',\n",
       " 54: 'different',\n",
       " 55: 'kind',\n",
       " 56: 'democrat',\n",
       " 57: 'republicans',\n",
       " 58: 'were',\n",
       " 59: 'set',\n",
       " 60: 'choose',\n",
       " 61: 'tuesday',\n",
       " 62: 'among',\n",
       " 63: 'three',\n",
       " 64: 'leading',\n",
       " 65: 'senate',\n",
       " 66: 'candidates',\n",
       " 67: 'hard-fought',\n",
       " 68: 'primary',\n",
       " 69: 'contest',\n",
       " 70: 'physician',\n",
       " 71: 'celebrity',\n",
       " 72: 'mehmet',\n",
       " 73: 'oz,',\n",
       " 74: 'backed',\n",
       " 75: 'by',\n",
       " 76: 'trump;',\n",
       " 77: 'financier',\n",
       " 78: 'david',\n",
       " 79: 'mccormick;',\n",
       " 80: 'upstart',\n",
       " 81: 'kathy',\n",
       " 82: 'barnette,',\n",
       " 83: 'who',\n",
       " 84: 'on',\n",
       " 85: 'jan',\n",
       " 86: '6,',\n",
       " 87: '2021,',\n",
       " 88: 'participated',\n",
       " 89: '“stop',\n",
       " 90: 'steal”',\n",
       " 91: 'rally',\n",
       " 92: 'preceded',\n",
       " 93: 'violent',\n",
       " 94: 'assault',\n",
       " 95: 'us',\n",
       " 96: 'capitol'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow2 = {}\n",
    "\n",
    "for k, v in bow.items():\n",
    "    bow2[v] = k\n",
    "\n",
    "bow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3],\n",
       " [4, 3, 1, 5, 6],\n",
       " [4,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  4,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  2,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  4,\n",
       "  26,\n",
       "  14,\n",
       "  27,\n",
       "  28,\n",
       "  8,\n",
       "  4,\n",
       "  29,\n",
       "  30,\n",
       "  1,\n",
       "  31,\n",
       "  4,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  33,\n",
       "  2,\n",
       "  37,\n",
       "  38,\n",
       "  2,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  2,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  34,\n",
       "  8,\n",
       "  47,\n",
       "  25,\n",
       "  2,\n",
       "  48,\n",
       "  49,\n",
       "  28,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  20,\n",
       "  53,\n",
       "  2,\n",
       "  54,\n",
       "  55,\n",
       "  11,\n",
       "  56],\n",
       " [57,\n",
       "  58,\n",
       "  59,\n",
       "  17,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  51,\n",
       "  2,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  14,\n",
       "  70,\n",
       "  43,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  43,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  51,\n",
       "  4,\n",
       "  89,\n",
       "  4,\n",
       "  90,\n",
       "  91,\n",
       "  28,\n",
       "  92,\n",
       "  4,\n",
       "  93,\n",
       "  94,\n",
       "  84,\n",
       "  4,\n",
       "  95,\n",
       "  96]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "\n",
    "for doc in data:\n",
    "    l = []\n",
    "    for word in doc:\n",
    "        l.append(bow[word])\n",
    "    X.append(l)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 원-핫 인코딩 (one-hot Encoding)\n",
    "자연어를 컴퓨터가 처리하도록 문자를 기계가 이해할수있는 숫자형태로 바꾸는 그과정을 임베딩(Embedding) 이라고합니다\n",
    "\n",
    "\n",
    "- 원-핫 인코딩은 단어 집합의 크기를 벡터의 차원으로 하고, 표현하고 싶은 단어의 인덱스에 1의 값을 부여하고, 다른 인덱스에는 0을 부여하는 벡터 표현 방식입니다.\n",
    "\n",
    "- 한자리만 맞는걸 원-핫 인코딩이라고 말한다.\n",
    "\n",
    "\n",
    "ex)\n",
    "|단어|단어인덱스|원-핫 벡터|\n",
    "|----|----------|----------|\n",
    "|you|0|[1,0,0,0,0,0]|\n",
    "|say|1|[0,1,0,0,0,0]|\n",
    "|goodbye|2|[0,0,1,0,0,0]|\n",
    "|and|3|[0,0,0,1,0,0]|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.]]),\n",
       " array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.]]),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.]])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원핫인코딩\n",
    "\n",
    "X2 = []\n",
    "\n",
    "for x in X:\n",
    "    a = np.eye(n + 1)[x]\n",
    "    X2.append(a)\n",
    "\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(n + 1)[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 직접 데이터 가져와서 해보기\n",
    "#### https://github.com/rickiepark/introduction_to_ml_with_python/blob/master/data/aclImdb_v1.tar.gz\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "imdb_train = load_files('data/aclImdb/train/')\n",
    "imdb_test = load_files('data/aclImdb/test/')\n",
    "\n",
    "np.save('imdb.npy', [imdb_train, imdb_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sklearn.utils.Bunch, sklearn.utils.Bunch)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(imdb_train), type(imdb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 25000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(imdb_train.data), len(imdb_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 25000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(imdb_test.data), len(imdb_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train.data[0].decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <br> 제거\n",
    "\n",
    "text_train = [s.decode().replace('<br />', '') for s in imdb_train.data]\n",
    "len(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train = imdb_train.target\n",
    "display(y_train.shape, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 뭘 더해야 12500 나오는거지?,,\n",
    "# -> 아,, y_train 하면 1,0.....0,0,0 이렇게 나오니깐 1만 더하면 12500나오는거네\n",
    "\n",
    "sum(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test = [s.decode().replace('<br />', '') for s in imdb_test.data] \n",
    "len(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test = imdb_test.target\n",
    "display(y_test.shape, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(text_train)\n",
    "X_train = vect.transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x75911 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3431163 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict, 75911)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vect.vocabulary_), len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero 75669\n",
      "day 16986\n",
      "leads 38653\n",
      "you 75381\n",
      "to 68091\n",
      "think 67468\n",
      "even 23059\n",
      "re 54503\n",
      "why 73998\n",
      "two 69757\n",
      "boys 8922\n"
     ]
    }
   ],
   "source": [
    "for i, (k, v) in enumerate(vect.vocabulary_.items()):\n",
    "    print(k, v)\n",
    "    if i == 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero 75669\n",
      "day 16986\n",
      "leads 38653\n",
      "you 75381\n",
      "to 68091\n",
      "think 67468\n",
      "even 23059\n",
      "re 54503\n",
      "why 73998\n",
      "two 69757\n",
      "boys 8922\n",
      "young 75392\n",
      "men 42764\n",
      "would 74762\n",
      "do 19634\n",
      "what 73731\n",
      "they 67409\n",
      "did 18588\n",
      "commit 13888\n",
      "mutual 45268\n",
      "suicide 65104\n",
      "via 72211\n",
      "slaughtering 61588\n",
      "their 67280\n",
      "classmates 12958\n",
      "it 35211\n",
      "captures 10809\n",
      "must 45209\n",
      "be 6512\n",
      "beyond 7341\n",
      "bizarre 7716\n",
      "mode 43993\n",
      "of 47352\n",
      "being 6852\n",
      "for 25839\n",
      "humans 32540\n",
      "who 73935\n",
      "have 30570\n",
      "decided 17219\n",
      "withdraw 74379\n",
      "from 26582\n",
      "common 13907\n",
      "civility 12845\n",
      "in 33505\n",
      "order 47900\n",
      "define 17460\n",
      "own 48610\n",
      "world 74699\n",
      "coupled 15414\n",
      "destruction 18214\n",
      "is 35099\n",
      "not 46714\n",
      "perfect 49947\n",
      "movie 44779\n",
      "but 10096\n",
      "given 28034\n",
      "money 44193\n",
      "time 67883\n",
      "the 67244\n",
      "filmmaker 24942\n",
      "and 3375\n",
      "actors 1741\n",
      "had 29807\n",
      "remarkable 55513\n",
      "product 52605\n",
      "terms 67035\n",
      "explaining 23541\n",
      "motives 44676\n",
      "actions 1723\n",
      "murderers 45110\n",
      "better 7288\n",
      "than 67198\n",
      "elephant 21607\n",
      "film 24904\n",
      "that 67222\n",
      "gets 27726\n",
      "under 70279\n",
      "our 48156\n",
      "rationalistic 54367\n",
      "skin 61440\n",
      "far 24147\n",
      "almost 2880\n",
      "anything 3859\n",
      "are 4269\n",
      "likely 39336\n",
      "see 59385\n",
      "flawed 25360\n",
      "honest 31970\n",
      "with 74378\n",
      "terrible 67049\n",
      "honesty 31972\n",
      "words 74651\n",
      "can 10580\n",
      "describe 18072\n",
      "how 32347\n",
      "bad 5669\n",
      "this 67505\n",
      "explain 23537\n",
      "by 10181\n",
      "writing 74886\n",
      "only 47657\n",
      "too 68298\n",
      "yourself 75410\n",
      "get 27716\n",
      "at 4910\n",
      "grip 29165\n",
      "horrible 32153\n",
      "really 54595\n",
      "recommend 54838\n",
      "there 67358\n",
      "so 62205\n",
      "many 41424\n",
      "clichés 13089\n",
      "mistakes 43840\n",
      "all 2767\n",
      "other 48119\n",
      "negative 45881\n",
      "things 67465\n",
      "imagine 33167\n",
      "here 31132\n",
      "will 74126\n",
      "just 36334\n",
      "make 41016\n",
      "cry 16123\n",
      "start 63760\n",
      "technical 66696\n",
      "first 25130\n",
      "lot 40076\n",
      "regarding 55184\n",
      "airplane 2471\n",
      "won 74533\n",
      "list 39560\n",
      "them 67292\n",
      "mention 42834\n",
      "coloring 13675\n",
      "plane 50966\n",
      "didn 18599\n",
      "manage 41189\n",
      "show 60687\n",
      "an 3284\n",
      "airliner 2464\n",
      "colors 13685\n",
      "fictional 24775\n",
      "airline 2463\n",
      "instead 34399\n",
      "used 71506\n",
      "747 949\n",
      "painted 48788\n",
      "original 47979\n",
      "boeing 8320\n",
      "livery 39648\n",
      "very 72163\n",
      "plot 51165\n",
      "stupid 64708\n",
      "has 30449\n",
      "been 6723\n",
      "done 19895\n",
      "times 67903\n",
      "before 6762\n",
      "much 44890\n",
      "ridiculous 56540\n",
      "moments 44150\n",
      "lost 40073\n",
      "count 15363\n",
      "early 21050\n",
      "also 2933\n",
      "was 73209\n",
      "on 47611\n",
      "guys 29674\n",
      "side 60905\n",
      "because 6638\n",
      "good 28490\n",
      "were 73627\n",
      "executive 23363\n",
      "decision 17235\n",
      "should 60662\n",
      "without 74402\n",
      "doubt 20115\n",
      "choice 12413\n",
      "over 48333\n",
      "one 47628\n",
      "turbulence 69575\n",
      "movies 44805\n",
      "fact 23871\n",
      "every 23105\n",
      "everyone 23112\n",
      "plays 51074\n",
      "part 49250\n",
      "pretty 52340\n",
      "well 73581\n",
      "little 39620\n",
      "nice 46197\n",
      "belushi 6982\n",
      "chance 11756\n",
      "live 39633\n",
      "his 31569\n",
      "life 39251\n",
      "differently 18640\n",
      "ends 22147\n",
      "up 71330\n",
      "realizing 54590\n",
      "he 30665\n",
      "going 28383\n",
      "as 4616\n",
      "or 47846\n",
      "maybe 42121\n",
      "shows 60715\n",
      "us 71492\n",
      "we 73388\n",
      "ought 48149\n",
      "take 66222\n",
      "advantage 2016\n",
      "opportunities 47793\n",
      "ones 47636\n",
      "cannot 10666\n",
      "if 33013\n",
      "video 72287\n",
      "around 4446\n",
      "10 40\n",
      "investment 34899\n",
      "highly 31393\n",
      "talented 66257\n",
      "filmmakers 24943\n",
      "germany 27674\n",
      "now 46821\n",
      "none 46565\n",
      "associated 4815\n",
      "producers 52602\n",
      "actually 1754\n",
      "invest 34885\n",
      "something 62466\n",
      "like 39327\n",
      "could 15333\n",
      "made 40762\n",
      "films 24956\n",
      "budget 9709\n",
      "garbage 27200\n",
      "entertaining 22391\n",
      "seven 59866\n",
      "grown 29306\n",
      "running 57586\n",
      "dwarfs 20926\n",
      "pretending 52322\n",
      "funny 26793\n",
      "though 67571\n",
      "producer 52599\n",
      "happens 30225\n",
      "oldest 47529\n",
      "guy 29670\n",
      "bunch 9875\n",
      "playing 51064\n",
      "youngest 75398\n",
      "dwarf 20923\n",
      "filled 24891\n",
      "scream 59044\n",
      "captions 10796\n",
      "saying 58503\n",
      "supposed 65434\n",
      "laugh 38479\n",
      "hard 30269\n",
      "believe 6910\n",
      "crap 15617\n",
      "comedy 13768\n",
      "people 49873\n",
      "stood 64233\n",
      "left 38778\n",
      "cinema 12710\n",
      "30 664\n",
      "minutes 43588\n",
      "into 34767\n",
      "same 58060\n",
      "wasting 73258\n",
      "my 45289\n",
      "pain 48770\n",
      "ve 71924\n",
      "evidence 23133\n",
      "confirmed 14367\n",
      "suspicions 65615\n",
      "kids 37084\n",
      "14 172\n",
      "22 571\n",
      "put 53461\n",
      "dvd 20906\n",
      "titanic 68027\n",
      "fantastic 24128\n",
      "state 63785\n",
      "art 4524\n",
      "mega 42591\n",
      "screen 59059\n",
      "home 31882\n",
      "entertainment 22393\n",
      "type 69787\n",
      "deal 17063\n",
      "seen 59414\n",
      "moment 44145\n",
      "kate 36673\n",
      "leo 38954\n",
      "celine 11510\n",
      "dion 18833\n",
      "most 44626\n",
      "felt 24566\n",
      "whole 73944\n",
      "shortly 60644\n",
      "after 2211\n",
      "epic 22534\n",
      "started 63761\n",
      "restless 56076\n",
      "some 62444\n",
      "asking 4701\n",
      "others 48123\n",
      "call 10427\n",
      "when 73781\n",
      "iceberg 32887\n",
      "appears 4004\n",
      "hour 32302\n",
      "half 29943\n",
      "girls 27993\n",
      "still 64090\n",
      "shouting 60674\n",
      "stampede 63637\n",
      "followed 25741\n",
      "came 10493\n",
      "back 5602\n",
      "sinking 61222\n",
      "sat 58334\n",
      "open 47733\n",
      "mouthed 44757\n",
      "emitting 21913\n",
      "ohs 47460\n",
      "outs 48272\n",
      "thought 67573\n",
      "burst 10013\n",
      "scene 58658\n",
      "hours 32305\n",
      "waiting 72962\n",
      "bloody 8089\n",
      "thing 67457\n",
      "sink 61218\n",
      "about 1354\n",
      "rest 56060\n",
      "dr 20236\n",
      "zivagho 75763\n",
      "instance 34391\n",
      "similar 61097\n",
      "takes 66237\n",
      "place 50922\n",
      "within 74397\n",
      "period 49991\n",
      "teaches 66642\n",
      "spit 63119\n",
      "look 39951\n",
      "faces 23849\n",
      "hands 30141\n",
      "supposedly 65435\n",
      "creme 15777\n",
      "de 17031\n",
      "la 37924\n",
      "class 12937\n",
      "dining 18805\n",
      "room 57156\n",
      "ship 60454\n",
      "historical 31593\n",
      "details 18232\n",
      "find 25008\n",
      "storyline 64301\n",
      "thin 67455\n",
      "introduce 34805\n",
      "guns 29601\n",
      "shootings 60593\n",
      "real 54564\n",
      "standards 63652\n",
      "efforts 21368\n",
      "focus 25676\n",
      "special 62888\n",
      "effects 21343\n",
      "opening 47737\n",
      "week 73475\n",
      "went 73621\n",
      "become 6661\n",
      "highest 31380\n",
      "grossing 29250\n",
      "know 37474\n",
      "sub 64778\n",
      "par 49042\n",
      "television 66833\n",
      "pilot 50707\n",
      "delivers 17651\n",
      "great 28977\n",
      "springboard 63330\n",
      "sci 58899\n",
      "fi 24747\n",
      "fans 24109\n",
      "ideal 32930\n",
      "program 52670\n",
      "deliver 17642\n",
      "series 59774\n",
      "spectacular 62932\n",
      "having 30585\n",
      "intelligent 34506\n",
      "interesting 34589\n",
      "script 59106\n",
      "doesn 19733\n",
      "hurt 32679\n",
      "either 21485\n",
      "stargate 63720\n",
      "sg1 59953\n",
      "currently 16339\n",
      "favorite 24367\n",
      "programs 52681\n",
      "way 73362\n",
      "telling 66846\n",
      "story 64290\n",
      "found 26114\n",
      "rather 54354\n",
      "odd 47305\n",
      "jumped 36272\n",
      "through 67654\n",
      "no 46465\n",
      "idea 32929\n",
      "whats 73743\n",
      "happening 30223\n",
      "anyway 3861\n",
      "line 39445\n",
      "although 2974\n",
      "simple 61127\n",
      "touching 68518\n",
      "met 43010\n",
      "someone 62451\n",
      "fell 24545\n",
      "love 40154\n"
     ]
    }
   ],
   "source": [
    "for i, (k, v) in enumerate(vect.vocabulary_.items()):\n",
    "    print(k, v)\n",
    "    if k == 'love': break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40154"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.vocabulary_['love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "75911"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['00', '000', '0000000000001', '00001', '00015']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['doppelgangers', 'doppelgänger', 'dopplebangers', 'doppleganger', 'doppler']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " 'burress',\n",
       " 'dop',\n",
       " 'hallucinogenics',\n",
       " 'looping',\n",
       " 'periphery',\n",
       " 'shaffer',\n",
       " 'una']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "display(type(feature_names), len(feature_names))\n",
    "display(feature_names[:5], feature_names[20010:20015], feature_names[::10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 75911)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=500)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=0.1, max_iter=500)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87884"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97504"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (75911,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = model.coef_[0] # 기울기 값\n",
    "type(w), w.shape # 값이 크면... 값도 75911 단어수고 75911,, 기울기 값이 크면 긍정효과를 나타낸다... 왜? 기울기 값이 작으면 부정적 아래 뽑아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "fn = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['worst', 'waste', 'awful', 'disappointment', 'poorly', 'boring',\n",
       "       'lacks', 'disappointing', 'mess', 'horrible', 'avoid', 'worse',\n",
       "       'fails', 'dull', 'save', 'poor', 'laughable', 'unfortunately',\n",
       "       'terrible', 'lame'], dtype='<U74')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer = w.argsort()\n",
    "\n",
    "fn[indexer[:20]] # 큰 음수값들, 즉 부정적인 영향을 끼침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['excellent', 'perfect', 'refreshing', 'superb', 'wonderfully',\n",
       "       'funniest', 'surprisingly', 'wonderful', 'rare', 'favorite',\n",
       "       'enjoyable', 'amazing', 'loved', 'today', 'highly', 'incredible',\n",
       "       'enjoyed', 'subtle', 'brilliant', 'gem'], dtype='<U74')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn[indexer[-1:-21:-1]] # 큰 양수값들, 즉 긍정적인영향을 끼침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
